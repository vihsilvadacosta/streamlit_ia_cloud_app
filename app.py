import streamlit as st
import requests
from PIL import Image

st.set_page_config(page_title="Gerador de Testes para Chatbot (Cloud)", layout="centered")

st.title("ü§ñ Gerador de Cen√°rios de Teste para Chatbot")
st.markdown("Gere cen√°rios no formato **Dado que... Quando... Ent√£o...** com IA gratuita da Hugging Face.")

# Entrada de dados
api_token = st.text_input("üîê Token da Hugging Face (https://huggingface.co/settings/tokens)", type="password")
bot_name = st.text_input("üß† Nome do Bot", placeholder="Ex: Chatbot Citro√´n")
objetivo = st.text_area("üéØ Objetivo do fluxo", placeholder="Ex: Agendar revis√£o para ve√≠culo...")
contexto = st.text_area("üìÑ Descri√ß√£o do fluxo", placeholder="Ex: Usu√°rio inicia a conversa, escolhe a data...")
tipo_teste = st.multiselect("üîç Tipos de teste desejados", ["Principal", "Alternativo", "Exce√ß√£o"], default=["Principal", "Alternativo", "Exce√ß√£o"])
imagem = st.file_uploader("üìé (Opcional) Anexe imagem do Figma com o fluxo", type=["png", "jpg", "jpeg"])

if imagem:
    st.image(Image.open(imagem), caption="Imagem do fluxo (Figma)", use_column_width=True)

# Gera√ß√£o do prompt
def gerar_prompt(bot_name, objetivo, contexto, tipos, imagem_presente):
    tipos_formatado = ', '.join(tipos)
    extra = "Foi anexada uma imagem representando o fluxo do chatbot, extra√≠da do Figma." if imagem_presente else ""
    return (
        f"Voc√™ √© um especialista em QA. Crie cen√°rios de teste no formato Gherkin (Dado que... Quando... Ent√£o...) "
        f"para o chatbot \"{bot_name}\".\n\n"
        f"Objetivo: {objetivo}\n"
        f"Fluxo textual descrito: {contexto}\n"
        f"Tipos de teste solicitados: {tipos_formatado}\n"
        f"{extra}\n\n"
        f"Crie pelo menos:\n"
        f"- 2 cen√°rios principais\n"
        f"- 1 alternativo\n"
        f"- 1 de exce√ß√£o\n\n"
        f"Use linguagem clara e profissional. Separe os cen√°rios por tipo."
    )

API_URL = "https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium"

if st.button("üöÄ Gerar Cen√°rios com IA"):
    if not api_token:
        st.error("‚ö†Ô∏è Forne√ßa seu token da Hugging Face.")
    elif not bot_name or not objetivo or not contexto:
        st.error("‚ö†Ô∏è Preencha todos os campos obrigat√≥rios.")
    else:
        prompt = gerar_prompt(bot_name, objetivo, contexto, tipo_teste, imagem is not None)
        st.info("‚è≥ Enviando para IA da Hugging Face...")

        # üëá agora sim: api_token j√° existe
        headers = {
            "Authorization": f"Bearer {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}",
            "Content-Type": "application/json"
        }

        payload = {
            "inputs": prompt.strip()
        }

        try:
            response = requests.post(API_URL, headers=headers, json=payload)
            if response.status_code != 200:
                st.error(f"Erro {response.status_code} - {response.text}")
            else:
                result = response.json()
                output = result[0]["generated_text"].strip()
                st.success("‚úÖ Cen√°rios gerados com sucesso!")
                st.code(output, language="gherkin")
        except Exception as e:
            st.error(f"Erro ao chamar a IA: {e}")

